========================================
 Real-Time Hand & Object Detection with
        LLM Scene Narration
========================================

DESCRIPTION
-----------
This project blends computer vision and language reasoning to create a real-time scene understanding system. Using your webcam, it detects objects with YOLOv8, tracks hands with MediaPipe, and sends that information to a Groq LLM to generate a short natural-language description of what is happening in the scene.

The application displays:
- Color-coded bounding boxes for detected objects
- Hand center markers for up to two hands
- Automatically wrapped LLM-generated text for readability
- Smooth, real-time performance in a resizable OpenCV window

PURPOSE
-------
This project demonstrates how computer vision and language models can work together to interpret live video. It serves as a compact example of multimodal AIâ€”combining detection, tracking, and reasoning into one cohesive system.

TECHNOLOGIES USED
-----------------
- YOLOv8 (object detection)
- MediaPipe (hand tracking)
- Groq LLM (scene narration)
- OpenCV (real-time display)

========================================
